# doc_generator.py

from llm_model import LLMModel

class DocGenerator:
    def __init__(self, model_name="deepseek-coder:1.3b", temperature=0.5, top_p=0.95, max_tokens=200):
        self.model = LLMModel(
            model_name=model_name,
            temperature=temperature,
            top_p=top_p,
            max_tokens=max_tokens
        )

    def create_prompt(self, code: str, language: str) -> str:
        """
        Creates a professional documentation prompt.
        """
        prompt = f"""You are an expert software engineer and technical writer.

Generate professional and detailed documentation for the following {language} code.

Focus on:
- **Overview** of the code
- **Functions/Methods** documentation (parameters, returns)
- **Classes/Modules** summary
- **Usage Examples** if obvious
- **Important Notes/Assumptions**

Output must be **well-structured**, step-by-step, and in **Markdown** format.

Here is the code:
```{language}
{code}
"""
        return prompt
    async def generate_documentation_stream(self, code: str, language: str):
            """
            Streams documentation generated by Ollama model.
            """
            prompt = self.create_prompt(code, language)
            async for chunk in self.model.generate_stream(prompt):
                yield chunk

        
